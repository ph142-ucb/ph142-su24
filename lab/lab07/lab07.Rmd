---
title: "Lab07: Confidence intervals and the dance of the p-values and p-hacking"
author: "name and student ID"
date: "Today's date"
output: pdf_document
---

**Run this chunk of code to load the autograder package!**
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(testthat)
```

### Instructions 
* Due date: Friday, July 26th at 10:00pm PST with a 2 hour grace period.
* Late penalty: 50% late penalty if submitted within 24 hours of due date, no marks for assignments submitted thereafter.
* Don't delete or add any `\newpage` tags.

Helpful hints:

- Every function you need to use was taught during lecture! So you may need to revisit the lecture code to help you along by opening the relevant files on Datahub. Alternatively, you may wish to view the code in the condensed PDFs posted on the course website. Good luck!

- Knit your file early and often to minimize knitting errors! If you copy and paste code for the slides, you are bound to get an error that is hard to diagnose. Typing out the code is the way to smooth knitting! We recommend knitting your file each time after you write a few sentences/add a new code chunk, so you can detect the source of knitting errors more easily. This will save you and the GSIs from frustration! You must knit correctly before submitting.*

- If your code runs off the page of the knitted PDF then you will LOSE POINTS! To avoid this, have a look at your knitted PDF and ensure all the code fits in the file (you can easily view it on Gradescope via the provided link after submitting). If it doesn't look right, go back to your .Rmd file and add spaces (new lines) using the return or enter key so that the code runs onto the next line.

- Useful mathematical notation in markdown:

$$\mu$$

$$\sigma$$
\newpage

## Part 1: Confidence intervals

Recall the Alameda dataset from our prior labs: suppose you had a data frame containing the **entire population** of all residents of Alameda County. There are data on four variables:

1.  Born either out (=1) versus in (=0) the county.
2.  Number of siblings (integer)
3.  Number of visits to the hospital last year
4.  Height (in inches)

Today we will focus on the height variable to construct confidence intervals from many samples.

Read in the data, `L07_Alameda.csv` (it lives in the data folder) and assign it to the name `alameda_pop`.

```
BEGIN QUESTION
name: p0
manual: true
```  

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(readr)

#### YOUR CODE GOES HERE ####

# BEGIN SOLUTION NO PROMPT

alameda_pop <- read_csv("data/L07_Alameda.csv")

# END SOLUTION
```

**1. [1 point] Calculate the true (population) mean and standard deviation of the `height` variable in the Alameda population dataset. To do this, use a `dplyr` function to make a dataframe called `height_mean_sd` with the first column called `mean_height` and the second column called `sd_height`.**

```
BEGIN QUESTION
name: height_mean_sd
manual: false
points: 1
```

```{r height_mean_sd}
. = " # BEGIN PROMPT
height_mean_sd <- NULL # YOUR CODE HERE
height_mean_sd 
" # END PROMPT

# BEGIN SOLUTION NO PROMPT
height_mean_sd <- alameda_pop %>% summarize(mean_height = mean(height), sd_height = sd(height))

height_mean_sd
# END SOLUTION
```

```{r}
## Test ##
test_that("height_mean_sd_a", {
  expect_true(nrow(height_mean_sd) == 1 & 
  ncol(height_mean_sd) == 2)
  print("Checking: 1 row and 2 columns")
})
```

```{r}
## Test ##
test_that("height_mean_sd_b", {
  expect_true(class(height_mean_sd$mean_height) == 'numeric' &
               class(height_mean_sd$sd_height) == 'numeric')
  print("Checking: mean and standard deviation are numeric")
})
```

```{r}
## Test ##
test_that("height_mean_sd_c", {
  expect_true(all.equal(height_mean_sd$mean_height, 69.97705, tol = 0.01) &
              all.equal(height_mean_sd$sd_height, 2.786314, tol = 0.01))
  print("Checking: height mean and standard deviation are correct values")
})
```

**2. [1 point] Use `ggplot()` to make a histogram of `height`, assign it to the object `p2`, and comment on its distribution. Does it look Normally distributed?**

```
BEGIN QUESTION
name: p2
manual: false
points: 1
```

```{r histogram}
. = " # BEGIN PROMPT
p2 <- NULL # YOUR CODE HERE
p2
" # END PROMPT


# BEGIN SOLUTION NO PROMPT
p2 <- ggplot(alameda_pop, aes(x = height)) +
  geom_histogram()
# END SOLUTION

```

```{r}
## Test ##
test_that("p2a", {
  expect_true("ggplot" %in% class(p2))
  print("Checking: p2 is a ggplot")
})
```

```{r}
## Test ##
test_that("p2b", {
  expect_true(identical(p2$data, alameda_pop))
  print("Checking: Using alameda_pop data")
})
```

```{r}
## Test ##
test_that("p2c", {
  expect_true(rlang::quo_get_expr(p2$mapping$x) == "height")
  print("Checking: height is on the x-axis")
})
```

```{r}
## Test ##
test_that("p2d", {
  expect_true("GeomBar" %in% class(p2$layers[[1]]$geom))
  print("Checking: Made a histogram")
})
```

_Type your answer here, replacing this text._

**3. [1 point] Save the known population standard deviation of the `height` variable to the object called `known_pop_sd` below.**

```
BEGIN QUESTION
name: known_pop_sd
manual: false\
points: 1
```

```{r known_pop_sd}
. = " # BEGIN PROMPT
known_pop_sd <- NULL # YOUR CODE HERE
known_pop_sd
" # END PROMPT


# BEGIN SOLUTION NO PROMPT
known_pop_sd <- 2.786314	
# END SOLUTION

```

```{r}
## Test ##
test_that("known_pop_sd_a", {
  expect_true(class(known_pop_sd) == 'numeric')
  print("Checking: known population sd is numeric")
})
```

```{r}
## Test ##
test_that("known_pop_sd_b", {
  expect_true(all.equal(known_pop_sd, 2.786314, tol = 0.001))
  print("Checking: known population sd is the correct value")
})
```

Now suppose you *do not know* the population mean, but wanted to estimate it based on a sample. In this lab, we actually know the true value because we calculated it above. This way, we can see how well any one sample estimates the population mean and see how often the confidence intervals contain the mean across several repeated samples.

### Calculating the CI and looking at its performance

We are now going to compute (and enter into our master google sheet) 95% confidence intervals (CI) for sampling means of different sizes. For this lab we:

- Have a variable with an underlying Normal distribution
- Will take simple random samples (SRS) from this distribution
- Know the value of the population mean (from your calculation in the first code
chunk)

Thus, we satisfy the three conditions discussed in lecture for calculating a confidence interval when the underlying SD is known.

Recall the formula for the 95% confidence interval in this setting (hover your mouse within the double-dollar signs to see the formula or knit the file to read it more easily):

$$\bar{x} \pm 1.96 \times\frac{\sigma}{\sqrt{n}}$$
Where:

- $\bar{x}$ is the estimated mean based on your sample
- $\sigma$ is the known standard deviation `known_pop_sd`, that you saved earlier for the distribution of `height`
- $\sigma/\sqrt{n}$ is the standard error of the sampling distribution for $\bar{x}$
- 1.96 is the critical value for a 95% CI

You will take a few samples from the distribution of heights from the Alameda population dataset and calculate the mean of your sampled heights and its confidence interval using the above formula. We will then record this information into the google sheet and plot all the CIs when we have at least 20 of them.

Below are the links to the communal google sheets. The columns in the sheets are `sample_mean_heights`, `lower_CI`, `upper_CI`, `sample_size`, `your_name` and `sample_id`.
- 101 (Alma): https://docs.google.com/spreadsheets/d/1rkj6zFB05NVJtp6JvHmC7CdHKDabKrCaI5V5gCS7BNs/edit#gid=0
- 102 (Defne & Sylvia): https://docs.google.com/spreadsheets/d/1CCa-npOK90Oy8Xh0LNq5mRIJmDj655cYa7N5EKuit74/edit#gid=0
- 103/104 (Iris & Pari): https://docs.google.com/spreadsheets/d/1mYGysAp3b7uHcB7JsnXzjwSx-yPu7fl5TdCGqGDjktQ/edit#gid=0
- 105/106 (Nola): https://docs.google.com/spreadsheets/d/1V6zJJOQkhtLE2YyPDHdwgPDQ2Gt_tf_lODiG-0jk5O8/edit#gid=0

### Your task

**4. Randomly generate 3 simple random samples of size $n = 10$ from the population. Calculate the average height for each of your samples. We wrote code to start you off, but you need to replace the three instances of NULL with calculations to compute the sample mean (`sample_mean_heights`), the lower confidence interval (`lower_CI`) and the upper confidence interval (`upper_CI`).**

Hint: Review the above section for tips on how to calculate the CI if you forget. Once you do this, you can simply copy and paste 3 times to generate three randomly-drawn samples, the sample means, and confidence intervals.

```
BEGIN QUESTION
name: p4
manual: true
```

```{r sample_size_10}
. = " # BEGIN PROMPT
sample_size <- 10
critical_value <- 1.96
size_10 <- sample_n(alameda_pop, sample_size, replace = FALSE)
p8 <- size_10 %>% summarise(mean_heights = NULL) %>%
mutate(lower_CI = NULL,
       upper_CI = NULL
)
" # END PROMPT


# BEGIN SOLUTION NO PROMPT
sample_size <- 10
critical_value <- 1.96
size_10 <- sample_n(alameda_pop, sample_size, replace = FALSE)
p8 <- size_10 %>% summarise(mean_heights = mean(height)) %>%
mutate(lower_CI = mean_heights - critical_value*(known_pop_sd/sqrt(sample_size)),
       upper_CI = mean_heights + critical_value*(known_pop_sd/sqrt(sample_size))
)	

# END SOLUTION

```

Navigate to the google sheet for your lab and add the mean and its CI for your three samples. Once this is done enough times, the GSI can make a plot of the CIs and see how many contain the true value for the mean. Based on this plot:

- What proportion of the confidence intervals contain the mean? 

_Type your answer here, replacing this text._

Repeat this for a sample size of $n=50$. In the code chunk below, generalize your code from the previous chunk to create three samples, this time of size n = 50:

```{r sample-size-50}
# YOUR CODE HERE
```

After you calculated your 3 sample means, navigate to the google sheet and add your data to the sheet with $n=50$.

Once this is done, the GSI will plot these data, now with $n=50$

- What proportion of the confidence intervals contain the mean?

_Type your answer here, replacing this text._

- How do the average widths of the CI's compare for $n=50$ versus $n=10$?

_Type your answer here, replacing this text._

- What would happen to the confidence intervals if $n=500$?

_Type your answer here, replacing this text._

## Part 2

In this next section you will read articles from the internet about differences in p-values and confidence intervals. You will also review information about p-hacking and data dredging to bring you up-to-speed on some of the language used to talk about bad scientific practice around the misuse of p-values.

### Section 1:

To do: 

- Watch this 11-min Youtube video on p-hacking: https://www.youtube.com/watch?v=Gx0fAjNHb1M

- Read this Wikipedia article on data dredging: https://en.wikipedia.org/wiki/Data_dredging

- Read this Vox article about the Cornell food researcher: https://www.vox.com/science-and-health/2018/9/19/17879102/brian-wansink-cornell-food-brand-lab-retractions-jama

- Read this two-page ASA brief on statistical significance and p-values: https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf

**5. In your own words, what is p-hacking?**

```
BEGIN QUESTION
name: p5
manual: true
```

<!-- BEGIN SOLUTION -->
Manipulating your data to artificially manufacture significant p-values by choosing analysis strategies that are designed to make the p-values significant rather than the best analysis plan for the question.
<!-- END SOLUTION -->

\newpage

**6. In your own words, what is data dredging?**

```
BEGIN QUESTION
name: p6
manual: true
```

<!-- BEGIN SOLUTION -->
Performing many tests on the same data to find statistical signficance and only reporting the ones that come back significant without the context of all the tests that were insignificant.
<!-- END SOLUTION -->

\newpage

**7. One of these sources provides an example of p-hacking in epidemiology related to cancer clusters. Describe in your own words what the problem is.**

```
BEGIN QUESTION
name: p7
manual: true
```

<!-- BEGIN SOLUTION -->
A researcher has access to a bunch of demographic information about a particular town identified as a cancer cluster. In actuality, none of these variables may have any correlation with the increased risk of cancer. If you were to set a significance level of .01 then perform 100 tests on each of these 100 covariates to find its connection to cancer, it is likely that at least 1 of these tests will be reveal a significant relationship just by chance.
<!-- END SOLUTION -->

\newpage

**8. What are three practices noted in one of the articles to reduce p-hacking? Name each one and describe them in 1-2 sentences.**

```
BEGIN QUESTION
name: p8
manual: true
```

<!-- BEGIN SOLUTION -->
Pre-registration of study designs: Having scientisists commit to a design and analysis plan before the data is collected. 

Open data sharing: Sharing data publicly (when possible) to allow for analyses to be repeated and checked even when the results have already been peer-reviewed.

Registered replication reports: Replicating (exactly or conceptually) already established findings to ensure and scrutinize the result.
<!-- END SOLUTION -->

\newpage

**9. One of the sources give a correction method for calculating p-values when you are going to conduct multiple tests. What is the name of the method? Write the equation for this correction.**

```
BEGIN QUESTION
name: p9
manual: true
```

<!-- BEGIN SOLUTION -->
Bonferroni Correction: Significant level / number of tests
<!-- END SOLUTION -->

\newpage

Please watch the video here:

https://www.youtube.com/watch?reload=9&v=5OL1RqHrZQ8

With captions: https://youtu.be/hes_5Xds8_U

**10. Which p-value is mentioned as leading to “Elation”?**

```
BEGIN QUESTION
name: p10
manual: true
```

<!-- BEGIN SOLUTION -->
0.001
<!-- END SOLUTION -->

\newpage

**11. How big was the “true” difference in the imaginary experiment described?**

```
BEGIN QUESTION
name: p11
manual: true
```

<!-- BEGIN SOLUTION -->
10 (or .5 sd)
<!-- END SOLUTION -->

\newpage

**12. Which measure gave a better estimate of the variability in results over multiple simulated studies?**

```
BEGIN QUESTION
name: p12
manual: true
```

<!-- BEGIN SOLUTION -->
Confidence intervals
<!-- END SOLUTION -->

### Submission

For assignments in this class, you'll be submitting using the **Terminal** tab in the pane below. In order for the submission to work properly, make sure that:

1. Any image files you add that are needed to knit the file are in the `src` folder and file paths are specified accordingly.
2. You **have not changed the file name** of the assignment.
3. The file knits properly.

Once you have checked these items, you can proceed to submit your assignment.

1. Click on the **Terminal** tab in the pane below.
2. Copy-paste the following line of code into the terminal and press enter.

cd; cd ph142-su24/lab/lab07; python3 turn_in.py

3. Follow the prompts to enter your Gradescope username and password.
4. If the submission is successful, you should see "Submission successful!" appear as the output. **Check your submission on the Gradescope website to ensure that the autograder worked properly and you received credit for your correct answers. If you think the autograder is incorrectly grading your work, please post on piazza!**
5. If the submission fails, try to diagnose the issue using the error messages--if you have problems, post on Piazza under the post "Datahub Issues".

The late policy will be strictly enforced, **no matter the reason**, including submission issues, so be sure to submit early enough to have time to diagnose issues if problems arise.
